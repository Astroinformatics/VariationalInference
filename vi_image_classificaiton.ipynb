{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3a83c78",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Lab 14: Modern Variational Inference\n",
    "#### [Penn State Astroinformatics Summer School 2022](https://sites.psu.edu/astrostatistics/astroinfo-su22-program/)\n",
    "#### [Jeffrey Regier](https://regier.stat.lsa.umich.edu/)\n",
    "\n",
    "In this tutorial, we'll analyze images of stars using modern variational inference and PyTorch. First let's import some packages that we'll use throughout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1b6128-7e44-4c62-893c-e8a2c3d9244d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcd7eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.distributions import Pareto, Poisson, Normal\n",
    "\n",
    "_ = torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5cdc46d",
   "metadata": {},
   "source": [
    "## Generating the data\n",
    "For simplicity, and so that we can know the ground truth, we'll use synthetic data. Let's generate it. The next block of code defines a pixelated point spread function (PSF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68ba566",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 16  # the number of images in our dataset\n",
    "img_dim = 15  # the height and width of our images. must be odd\n",
    "\n",
    "psf_marginal = 1 + torch.arange(img_dim, dtype=torch.float32)\n",
    "half_dim = img_dim // 2\n",
    "psf_marginal[half_dim:] -= 2 * torch.arange(half_dim + 1)\n",
    "psf = torch.mm(psf_marginal.view(img_dim, 1), psf_marginal.view(1, img_dim))\n",
    "psf /= psf.sum()\n",
    "\n",
    "_ = plt.imshow(psf.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ecadc0",
   "metadata": {},
   "source": [
    "In our generative model, the flux for each star follows a Gaussian distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ced7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_flux = 100 / psf.max()\n",
    "flux_prior = Normal(10 * min_flux, 2 * min_flux)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41fbc04",
   "metadata": {},
   "source": [
    "To generate our synthetic dataset, let's draw the \"true\" fluxes of `n` stars. These are the latent values we'll subsequently aim to infer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba04d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_fluxes = flux_prior.sample([n])\n",
    "print(f\"flux mean: {true_fluxes.mean().item()}\")\n",
    "print(f\"flux sd: {true_fluxes.std().item()}\")\n",
    "print(f\"flux min: {true_fluxes.min().item()}\")\n",
    "print(f\"flux max: {true_fluxes.max().item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931d260f",
   "metadata": {},
   "source": [
    "In a realistic model of images of stars, a fixed background intensity is added to flux-scaled PSF to give the expected intensity of each pixel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022bb99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "background_intensity = 3 * min_flux\n",
    "star_intensity = true_fluxes.view(n, 1, 1) * psf.view(1, img_dim, img_dim)\n",
    "true_intensity = background_intensity + star_intensity\n",
    "_ = plt.imshow(true_intensity[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7a6d09",
   "metadata": {},
   "source": [
    "Now let's draw some images of stars with the fluxes we've previously sampled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a28608",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = Poisson(true_intensity).sample()\n",
    "_ = plt.imshow(images[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbf5b10",
   "metadata": {},
   "source": [
    "## Numerical integration\n",
    "\n",
    "Numerical integration is a precursor to varational inference.\n",
    "Numerical integration approximates integrals by partitioning the domain into a grid, evaluating the integrand at each point of the grid, and averaging these values.\n",
    "In Bayesian inference, the integrand is the joint distribution: $$p(\\mathrm{fluxes}, \\mathrm{images}) = p(\\mathrm{fluxes}) \\, p(\\mathrm{images} \\mid \\mathrm{fluxes}).$$\n",
    "Integrating out the fluxes gives us $p(\\mathrm{images}).$\n",
    "Then, using Bayes rule, we can solve for the posterior, i.e.,\n",
    "$$p(\\mathrm{fluxes} \\mid \\mathrm{images}) = \\frac{p(\\mathrm{images} \\mid \\mathrm{fluxes}) \\, p(\\mathrm{fluxes})}{p(\\mathrm{images})}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deddea19",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_width = 100\n",
    "grid_size = 5000\n",
    "flux_grid = min_flux + torch.arange(grid_size) * bin_width\n",
    "\n",
    "rate = psf.view(1, img_dim, img_dim, 1) * flux_grid.view(1, 1, 1, grid_size)\n",
    "rate += background_intensity\n",
    "\n",
    "# conditional log likelihood (for each observed image and each flux grid point)\n",
    "images4d = images.view(n, img_dim, img_dim, 1)\n",
    "log_p_images_given_fluxes = Poisson(rate).log_prob(images4d).sum([1, 2])\n",
    "assert log_p_images_given_fluxes.shape == (n, grid_size)\n",
    "\n",
    "# joint log likelihood\n",
    "log_p_fluxes_and_images = log_p_images_given_fluxes + flux_prior.log_prob(flux_grid)\n",
    "assert log_p_fluxes_and_images.shape == (n, grid_size)\n",
    "\n",
    "# posterior log likelihood\n",
    "log_p_fluxes_given_images = min_flux + log_p_fluxes_and_images * bin_width\n",
    "assert log_p_fluxes_given_images.shape == (n, grid_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32020835",
   "metadata": {},
   "source": [
    "Comparing point estimates to the ground truth is one way to assess how well various inference methods are performing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981746ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flux_rmse(est_fluxes):\n",
    "    return (true_fluxes - est_fluxes).pow(2).mean().sqrt()\n",
    "\n",
    "print(f\"prior mean RMSE: {flux_rmse(flux_prior.mean)}\")\n",
    "\n",
    "ss_flux = (images - background_intensity).sum([1,2])\n",
    "print(f\"sky subtracted RMSE: {flux_rmse(ss_flux)}\")\n",
    "\n",
    "mle_flux = min_flux + 1 + log_p_images_given_fluxes.argmax(1) * bin_width\n",
    "print(f\"grid MLE RMSE: {flux_rmse(mle_flux)}\")\n",
    "\n",
    "map_flux = min_flux + 1 + log_p_fluxes_and_images.argmax(1) * bin_width\n",
    "print(f\"grid MAP RMSE: {flux_rmse(map_flux)}\")\n",
    "\n",
    "posterior_mean = (log_p_fluxes_given_images.softmax(1) * flux_grid.view(1, grid_size)).sum(1)\n",
    "print(f\"grid posterior mean RMSE: {flux_rmse(posterior_mean)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295cad1c",
   "metadata": {},
   "source": [
    "## Variational inference\n",
    "In variational inference, we attempt to find a distribution $q(\\mathrm{flux})$ that minimizes $$\\mathrm{KL}(q(\\mathrm{flux})\\, \\| \\, p(\\mathrm{flux} \\mid \\mathrm{images}).$$\n",
    "Below, we restrict $q$ to the the class of $n$-dimensional multivariate normal distributions that have a diagonal covariance matrix.\n",
    "The approximation $q$ is parameterized by a unique mean and standardization for each image.\n",
    "We compute stochastic gradients of the objective function using the reparameterization trick, and use stochastic gradient descent for optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508f357f",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_mean = nn.Parameter((images - background_intensity).sum([1,2]) + 5000)\n",
    "q_sd = nn.Parameter(torch.ones(n) * 100)\n",
    "\n",
    "optimizer = torch.optim.SGD([q_mean, q_sd], lr=100)\n",
    "num_samples = 64  # number of samples of q per image\n",
    "\n",
    "for i in range(3000):\n",
    "    q = Normal(q_mean, q_sd.clamp(1e-4))\n",
    "    z = q.rsample((num_samples,))\n",
    "    zt = z.permute(1, 0)\n",
    "\n",
    "    rate = psf.view(1, img_dim, img_dim, 1) * zt.view(n, 1, 1, num_samples)\n",
    "    rate += background_intensity\n",
    "    cond_ll = Poisson(rate)\n",
    "    \n",
    "    neg_elbo = q.log_prob(z).sum()\n",
    "    neg_elbo -= flux_prior.log_prob(z).sum()\n",
    "    neg_elbo -= cond_ll.log_prob(images.view(n, img_dim, img_dim, 1)).sum()\n",
    "    \n",
    "    if i % 200 == 0:\n",
    "        obj = neg_elbo.item() / num_samples\n",
    "        rmse = flux_rmse(q_mean)\n",
    "        print(f\"[{i}] objective: {obj}   rmse: {rmse}\")\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    neg_elbo.sum().backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d700a6",
   "metadata": {},
   "source": [
    "The approach above can be slow because it requires us to effectively solve a unique optimization problem for each image. Amortized inference is more efficient for large datasets. In amortized inference, the approximating distribution for each of the $n$ images is specified by shared neural network, called an encoder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bde34f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StarEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(img_dim * img_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 2),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, img_dim ** 2)\n",
    "        out = self.net(x)\n",
    "        q_mean = out[:, 0]\n",
    "        q_sd = out[:, 1].clamp(-6, 6).exp()\n",
    "        return Normal(q_mean, q_sd)\n",
    "    \n",
    "\n",
    "encoder = StarEncoder()\n",
    "optimizer = torch.optim.SGD(encoder.parameters(), lr=1e-3)\n",
    "\n",
    "mb = 8   # minibatch size\n",
    "num_samples = 64  # number of samples of q per image in the minibatch\n",
    "\n",
    "for i in range(30000):\n",
    "    indices = torch.randint(n, (mb,))\n",
    "    x = images[indices]\n",
    "\n",
    "    q = encoder(x)\n",
    "\n",
    "    z = q.rsample((num_samples,))\n",
    "    zt = z.permute(1, 0)\n",
    "    \n",
    "    rate = psf.view(1, img_dim, img_dim, 1) * zt.view(mb, 1, 1, num_samples)\n",
    "    rate = rate.clamp(0) + background_intensity\n",
    "    cond_ll = Poisson(rate)\n",
    "\n",
    "    neg_elbo = q.log_prob(z).sum()\n",
    "    neg_elbo -= flux_prior.log_prob(z).sum()\n",
    "    neg_elbo -= cond_ll.log_prob(x.view(mb, img_dim, img_dim, 1)).sum()\n",
    "\n",
    "    if i % 500 == 0:\n",
    "        obj = neg_elbo.item() * n / (mb * num_samples)\n",
    "        rmse = flux_rmse(encoder(images).mean)\n",
    "        print(f\"[{i}] objective: {obj}   rmse: {rmse}\")\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    neg_elbo.sum().backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6265d722",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
